{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600685431923",
   "display_name": "Python 3.7.7 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=50)"
   ]
  },
  {
   "source": [
    "# Self-Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, num_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_dim = num_dim\n",
    "\n",
    "        self.toqueries = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.tokeys = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.tovalues = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.unify_heads = nn.Linear(self.num_heads*self.num_dim, self.num_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_batch, num_words, num_dim = x.shape\n",
    "        num_heads = self.num_heads\n",
    "\n",
    "        queries = self.toqueries(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "        keys = self.tokeys(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "        values = self.tovalues(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "        keys = keys.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "        values = values.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "\n",
    "        queries = queries/(num_dim**(1/4))\n",
    "        keys = keys/(num_dim**(1/4))\n",
    "\n",
    "        raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        weights = torch.softmax(raw_weights, dim=2)\n",
    "\n",
    "        out = torch.bmm(weights, values).view(num_batch, num_heads, num_words, num_dim)\n",
    "        out = out.transpose(1, 2).contiguous().view(num_batch, num_words, num_heads*num_dim)\n",
    "        out = self.unify_heads(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "# Transformer Block"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_dim, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.num_dim = num_dim\n",
    "        self.sa = SelfAttention(self.num_heads, self.num_dim)\n",
    "        self.norm1 = nn.LayerNorm(self.num_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "                        nn.Linear(self.num_dim, 4*self.num_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(4*self.num_dim, self.num_dim)\n",
    "                        )\n",
    "        self.norm2 = nn.LayerNorm(self.num_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.sa(x)\n",
    "        out2 = self.norm1(out1+x)\n",
    "        out3 = self.mlp(out2)\n",
    "        final = self.norm2(out3+out2)\n",
    "        return final"
   ]
  },
  {
   "source": [
    "# IMDB data pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Home Room was a great movie if you've ever had drama in your life. It keeps you wanting to see more. Wondering what the secret Alicia is hiding. I think I watched that movie 6 times in a row and never lost interest. Plus I usually don't cry over movies but this one made me cry each time. I wish I could find more movies like that one. All in All I thought it was a great movie. The more you watch of it the more you become part of it. The very end is the part that really got me when she cried when getting her diploma, because it had her daughter's name on it. My heart felt as if it had shattered just then. And how her new friend came to comfort her when she hadn't gotten hers yet. I loved it so much."
    }
   ],
   "source": [
    "!head 'aclImdb/train/pos/45_10.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "trainposfiles = [join('aclImdb/train/pos/', f) for f in listdir('aclImdb/train/pos/') if isfile(join('aclImdb/train/pos/', f))]\n",
    "trainnegfiles = [join('aclImdb/train/neg/', f) for f in listdir('aclImdb/train/neg/') if isfile(join('aclImdb/train/neg/', f))]\n",
    "testposfiles = [join('aclImdb/test/pos/', f) for f in listdir('aclImdb/test/pos/') if isfile(join('aclImdb/test/pos/', f))]\n",
    "testnegfiles = [join('aclImdb/test/neg/', f) for f in listdir('aclImdb/test/neg/') if isfile(join('aclImdb/test/neg/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for x in trainposfiles:\n",
    "    f = open(x, \"r\")\n",
    "    train.append({\"review\": f.read(), \"sentiment\": 1})\n",
    "    f.close()\n",
    "for x in trainnegfiles:\n",
    "    f = open(x, \"r\")\n",
    "    train.append({\"review\": f.read(), \"sentiment\": 0})\n",
    "    f.close()\n",
    "for x in testposfiles:\n",
    "    f = open(x, \"r\")\n",
    "    test.append({\"review\": f.read(), \"sentiment\": 1})\n",
    "    f.close()\n",
    "for x in testnegfiles:\n",
    "    f = open(x, \"r\")\n",
    "    test.append({\"review\": f.read(), \"sentiment\": 0})\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(train)\n",
    "df2 = pd.DataFrame(test)\n",
    "df1.to_csv('train.csv', index=False)\n",
    "df2.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"train.json\", \"w\") as trainfile:  \n",
    "    json.dump(train, trainfile) \n",
    "\n",
    "with open(\"test.json\", \"w\") as testfile:  \n",
    "    json.dump(test, testfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "review = Field(sequential=True, tokenize=tokenize, use_vocab=True, lower=True, batch_first=True, fix_length=1024)\n",
    "sentiment = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\"review\": (\"review\", review), \"sentiment\": (\"sentiment\", sentiment)}\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "    path='/home/chirag_17bit012/Attention-Is-All-You-Get/data',\n",
    "    format='csv',\n",
    "    train='train.csv',\n",
    "    test='test.csv',\n",
    "    fields=[('review', review), ('sentiment', sentiment)],\n",
    "    skip_header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review.build_vocab(train_data, vectors=\"glove.6B.50d\")\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\ntorch.Size([8, 1024])\n"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for b in train_iterator:\n",
    "    cnt+=1\n",
    "    print(b.review.size())\n",
    "    if cnt==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = review.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "101513"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n        ...,\n        [-0.3564, -0.8063,  0.2048,  ..., -0.0914,  0.2320,  0.7523],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "embed = nn.Embedding(len(vocab), 50)\n",
    "embed.weight.data.copy_(vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([8, 1024, 50])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "embed(b.review).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embed, num_dim, device, max_len=10000):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.device = device\n",
    "        pe = torch.zeros(max_len, num_dim)\n",
    "        for pos in range(max_len):\n",
    "            for i in range(0, num_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/num_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/num_dim)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        num_words = x.shape[1]\n",
    "        word_embedding = self.embed(x).to(self.device)\n",
    "        postional_encoding = self.pe[ :, :num_words]\n",
    "        postional_encoding.requires_grad = False\n",
    "        postional_encoding = postional_encoding.to(self.device)\n",
    "        return word_embedding + postional_encoding"
   ]
  },
  {
   "source": [
    "# Classification Transformer\n",
    "![image](http://peterbloem.nl/files/transformers/classifier.svg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTransformer(nn.Module):\n",
    "    def __init__(self, embed, device, num_blocks=1, num_dim=50, num_heads=8, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embbeding = Embedding(embed, num_dim, device)\n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(Transformer(num_dim, num_heads))\n",
    "        self.transformer_blocks = nn.Sequential(*blocks)\n",
    "        self.out = nn.Linear(num_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        embedded_input = self.embbeding(x)\n",
    "        output = self.transformer_blocks(embedded_input)\n",
    "        output = self.out(output.mean(dim=1))\n",
    "        return F.log_softmax(output, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 3125/3125 [05:52<00:00,  8.88it/s]\n  0%|          | 1/3125 [00:00<08:20,  6.24it/s]Epoch: 1, Training Loss: 5.5766, Validation Loss: 5.5514\n100%|██████████| 3125/3125 [05:56<00:00,  8.76it/s]\nEpoch: 2, Training Loss: 5.5603, Validation Loss: 5.5815\nDone\n"
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "num_heads = 8\n",
    "num_classes = 2\n",
    "num_blocks = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embed = embed\n",
    "model = ClassificationTransformer(embed, device, num_blocks=num_blocks, num_heads=num_heads, num_classes=num_classes).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train()\n",
    "    #try:\n",
    "    for train_obj in tqdm.tqdm(train_iterator):\n",
    "        x = train_obj.review.to(device)\n",
    "        y = train_obj.sentiment.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "    epoch_loss = running_loss / len(train_iterator)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): \n",
    "        for test_obj in test_iterator:\n",
    "            inp = test_obj.review.to(device)\n",
    "            tar = test_obj.sentiment.to(device)\n",
    "            preds = model(inp)\n",
    "            loss = criterion(preds, tar)\n",
    "            val_loss += loss.item() * batch_size\n",
    "\n",
    "\n",
    "    val_loss /= len(test_iterator)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))\n",
    "    #except Exception as e:\n",
    "    #    print(e)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ]
}