{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600598736504",
   "display_name": "Python 3.7.7 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=50)"
   ]
  },
  {
   "source": [
    "# Self-Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, num_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_dim = num_dim\n",
    "\n",
    "        self.toqueries = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.tokeys = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.tovalues = nn.Linear(self.num_dim, self.num_heads*self.num_dim, bias=False)\n",
    "        self.unify_heads = nn.Linear(self.num_heads*self.num_dim, self.num_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_batch, num_words, num_dim = x.shape\n",
    "        num_heads = self.num_heads\n",
    "\n",
    "        queries = self.toqueries(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "        keys = self.tokeys(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "        values = self.tovalues(x).view(num_batch, num_words, num_heads, num_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "        keys = keys.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "        values = values.transpose(1, 2).contiguous().view(num_batch*num_heads, num_words, num_dim)\n",
    "\n",
    "        queries = queries/(num_dim**(1/4))\n",
    "        keys = keys/(num_dim**(1/4))\n",
    "\n",
    "        raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        weights = torch.softmax(raw_weights, dim=2)\n",
    "\n",
    "        out = torch.bmm(weights, values).view(num_batch, num_heads, num_words, num_dim)\n",
    "        out = out.transpose(1, 2).contiguous().view(num_batch, num_words, num_heads*num_dim)\n",
    "        out = self.unify_heads(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "# Transformer Block"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_dim, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.num_dim = num_dim\n",
    "        self.sa = SelfAttention(self.num_heads, self.num_dim)\n",
    "        self.norm1 = nn.LayerNorm(self.num_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "                        nn.Linear(self.num_dim, 4*self.num_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(4*self.num_dim, self.num_dim)\n",
    "                        )\n",
    "        self.norm2 = nn.LayerNorm(self.num_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.sa(x)\n",
    "        out2 = self.norm1(out1+x)\n",
    "        out3 = self.mlp(out2)\n",
    "        final = self.norm2(out3+out2)\n",
    "        return final"
   ]
  },
  {
   "source": [
    "# IMDB data pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Home Room was a great movie if you've ever had drama in your life. It keeps you wanting to see more. Wondering what the secret Alicia is hiding. I think I watched that movie 6 times in a row and never lost interest. Plus I usually don't cry over movies but this one made me cry each time. I wish I could find more movies like that one. All in All I thought it was a great movie. The more you watch of it the more you become part of it. The very end is the part that really got me when she cried when getting her diploma, because it had her daughter's name on it. My heart felt as if it had shattered just then. And how her new friend came to comfort her when she hadn't gotten hers yet. I loved it so much."
    }
   ],
   "source": [
    "!head 'aclImdb/train/pos/45_10.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "trainposfiles = [join('aclImdb/train/pos/', f) for f in listdir('aclImdb/train/pos/') if isfile(join('aclImdb/train/pos/', f))]\n",
    "trainnegfiles = [join('aclImdb/train/neg/', f) for f in listdir('aclImdb/train/neg/') if isfile(join('aclImdb/train/neg/', f))]\n",
    "testposfiles = [join('aclImdb/test/pos/', f) for f in listdir('aclImdb/test/pos/') if isfile(join('aclImdb/test/pos/', f))]\n",
    "testnegfiles = [join('aclImdb/test/neg/', f) for f in listdir('aclImdb/test/neg/') if isfile(join('aclImdb/test/neg/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for x in trainposfiles:\n",
    "    f = open(x, \"r\")\n",
    "    train.append({\"review\": f.read(), \"sentiment\": 1})\n",
    "    f.close()\n",
    "for x in trainnegfiles:\n",
    "    f = open(x, \"r\")\n",
    "    train.append({\"review\": f.read(), \"sentiment\": 0})\n",
    "    f.close()\n",
    "for x in testposfiles:\n",
    "    f = open(x, \"r\")\n",
    "    test.append({\"review\": f.read(), \"sentiment\": 1})\n",
    "    f.close()\n",
    "for x in testnegfiles:\n",
    "    f = open(x, \"r\")\n",
    "    test.append({\"review\": f.read(), \"sentiment\": 0})\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(train)\n",
    "df2 = pd.DataFrame(test)\n",
    "df1.to_csv('train.csv', index=False)\n",
    "df2.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"train.json\", \"w\") as trainfile:  \n",
    "    json.dump(train, trainfile) \n",
    "\n",
    "with open(\"test.json\", \"w\") as testfile:  \n",
    "    json.dump(test, testfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "review = Field(sequential=True, tokenize=tokenize, use_vocab=True, lower=True, batch_first=True)\n",
    "sentiment = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\"review\": (\"review\", review), \"sentiment\": (\"sentiment\", sentiment)}\n",
    "train_data, test_data = TabularDataset.splits(\n",
    "    path='/home/chirag_17bit012/Attention-Is-All-You-Get/data',\n",
    "    format='csv',\n",
    "    train='train.csv',\n",
    "    test='test.csv',\n",
    "    fields=[('review', review), ('sentiment', sentiment)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review.build_vocab(train_data, vectors=\"glove.6B.50d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=16,\n",
    "    sort_key=lambda x: len(x.Text),\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([16, 873])\ntorch.Size([16, 1154])\ntorch.Size([16, 365])\ntorch.Size([16, 642])\ntorch.Size([16, 1120])\ntorch.Size([16, 804])\ntorch.Size([16, 882])\ntorch.Size([16, 392])\ntorch.Size([16, 420])\ntorch.Size([16, 398])\n"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for b in train_iterator:\n",
    "    cnt+=1\n",
    "    print(b.review.size())\n",
    "    if cnt==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = review.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "101513"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n        ...,\n        [-0.3564, -0.8063,  0.2048,  ..., -0.0914,  0.2320,  0.7523],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n       device='cuda:0')"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "embed = nn.Embedding(len(vocab), 50).to('cuda')\n",
    "embed.weight.data.copy_(vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([16, 398, 50])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "embed(b.review).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embed, num_dim, device, max_len=20000):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.device = device\n",
    "        pe = torch.zeros(max_len, num_dim)\n",
    "        for pos in range(max_len):\n",
    "            for i in range(0, num_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/num_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/num_dim)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        num_words = x.shape[1]\n",
    "        word_embedding = self.embed(x).to(self.device)\n",
    "        postional_encoding = self.pe[ :, :num_words]\n",
    "        postional_encoding.requires_grad = False\n",
    "        postional_encoding = postional_encoding.to(self.device)\n",
    "        return word_embedding + postional_encoding"
   ]
  },
  {
   "source": [
    "# Classification Transformer\n",
    "![image](http://peterbloem.nl/files/transformers/classifier.svg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTransformer(nn.Module):\n",
    "    def __init__(self, embed, device, num_dim=50, num_heads=8, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embbeding = Embedding(embed, num_dim, device)\n",
    "        self.transformer = Transformer(num_dim, num_heads)\n",
    "        self.out = nn.Linear(num_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        embedded_input = self.embbeding(x)\n",
    "        #print(embedded_input.get_device())\n",
    "        output = self.transformer(embedded_input)\n",
    "        output = self.out(output.mean(dim=1))\n",
    "        return F.log_softmax(output, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Embedding(101513, 50)\n  3%|â–Ž         | 43/1563 [00:01<00:42, 35.54it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.71 GiB (GPU 0; 31.74 GiB total capacity; 26.74 GiB already allocated; 2.45 GiB free; 27.94 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dc24c7bbfa61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-7d2e3e2ebc01>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0membedded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membbeding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(embedded_input.get_device())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3996f3ecf7e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7b19efd10544>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mraw_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.71 GiB (GPU 0; 31.74 GiB total capacity; 26.74 GiB already allocated; 2.45 GiB free; 27.94 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "num_heads = 8\n",
    "num_classes = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "embed = embed\n",
    "print(embed)\n",
    "model = ClassificationTransformer(embed, device, num_heads=num_heads, num_classes=num_classes).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train()\n",
    "    for obj in tqdm.tqdm(train_iterator): \n",
    "        x = obj.review.to(device)\n",
    "        y = obj.sentiment.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        error = loss(preds, y)\n",
    "        error.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += error.data * x.shape[0]\n",
    "\n",
    "    epoch_loss = running_loss / len(train_iterator)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    model.eval() \n",
    "    for test_obj in test_iterator:\n",
    "        x = test_obj.review.to(device)\n",
    "        y = test_obj.sentiment.to(device)\n",
    "        preds = model(x)\n",
    "        error = loss(preds, y)\n",
    "        val_loss += error.data * x.shape[0]\n",
    "\n",
    "    val_loss /= len(test_iterator)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 1.1633,  0.6877,  0.3475, -0.9342],\n         [ 1.2643, -0.3659, -0.2325,  3.3317],\n         [-0.1619, -1.1090,  0.5910, -0.3541],\n         [ 1.0268,  0.3485, -0.6662,  0.9243],\n         [ 0.6598,  0.0377, -0.3637, -0.6380],\n         [-1.0930, -0.6696, -0.2064,  1.2736]]])\n"
    }
   ],
   "source": [
    " a = torch.randn(1, 6, 4)\n",
    " print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-18bf08814031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}