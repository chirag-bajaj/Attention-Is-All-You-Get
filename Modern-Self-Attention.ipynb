{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600276521175",
   "display_name": "Python 3.7.7 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=50)"
   ]
  },
  {
   "source": [
    "# Single Head Self Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([6, 50])\ntorch.Size([1, 6, 50])\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "X = torch.stack((embedding_glove['the'], embedding_glove['cat'], embedding_glove['walks'], embedding_glove['on'], embedding_glove['the'], embedding_glove['street']))\n",
    "print(X.shape)\n",
    "#X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "X = X.view(1, X.shape[0], X.shape[1])\n",
    "print(X.shape)"
   ]
  },
  {
   "source": [
    "Every input vector ùê±i is used in three different ways in the self attention operation:\n",
    "\n",
    "It is compared to every other vector to establish the weights for its own output ùê≤i. (Query)\n",
    "It is compared to every other vector to establish the weights for the output of the j-th vector ùê≤j. (Key)\n",
    "It is used as part of the weighted sum to compute each output vector once the weights have been established. (Value)\n",
    "\n",
    " In other words, we add three k√ók weight matrices ùêñq, ùêñk,ùêñv and compute three linear transformations of each xi, for the three different parts of the self attention:\n",
    "$$ùê™_{i}=ùêñ_{q}ùê±_{i}\\;\\;\\;ùê§i=ùêñ_{k}ùê±_{i}\\;\\;\\;ùêØ_{i}=ùêñ_{v}ùê±_{i}$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "queries = nn.Linear(X.shape[2], X.shape[2], bias=False)\n",
    "keys = nn.Linear(X.shape[2], X.shape[2], bias=False)\n",
    "values = nn.Linear(X.shape[2], X.shape[2], bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries(X)\n",
    "keys = keys(X)\n",
    "values = values(X)"
   ]
  },
  {
   "source": [
    "$$w‚Ä≤_{ij}=ùê™_{i}^Tùê§_{j}$$\n",
    "\n",
    "The softmax function can be sensitive to very large input values. These kill the gradient, and slow down learning, or cause it to stop altogether. Since the average value of the dot product grows with the embedding dimension k, it helps to scale the dot product back a little to stop the inputs to the softmax function from growing too large:\n",
    "\n",
    "$$w‚Ä≤_{ij}=\\frac{ùê™_{i}^Tùê§_{j}}{‚àök}$$\n",
    "\n",
    "$$w_{ij}=softmax(w‚Ä≤_{ij})$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 6, 6])\n"
    }
   ],
   "source": [
    "queries = queries/(queries.shape[2]**(1/4))\n",
    "keys = keys/(keys.shape[2]**(1/4))\n",
    "\n",
    "raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n",
    "print(raw_weights.shape)\n",
    "\n",
    "weights = F.softmax(raw_weights, dim=2) "
   ]
  },
  {
   "source": [
    "We apply the self attention to the values:\n",
    "$$ùê≤_{i}=\\sum_{j}w_{ij}ùêØ_{j}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(weights, values)"
   ]
  },
  {
   "source": [
    "'out' is our output vector with self-attention. This approach gives the self-attention layer some controllable parameters, and allows it to modify the incoming vectors accordingly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Understanding of .contiguous()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(36, 1, 6)\nFalse\n"
    }
   ],
   "source": [
    "g = weights.transpose(1, 2)\n",
    "print(g.stride())\n",
    "print(g.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(36, 6, 1)\nTrue\n"
    }
   ],
   "source": [
    "g = g.contiguous()\n",
    "print(g.stride())\n",
    "print(g.is_contiguous())"
   ]
  },
  {
   "source": [
    "# Multi-Haeaded Self Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([6, 50])\ntorch.Size([1, 6, 50])\n"
    }
   ],
   "source": [
    "X = torch.stack((embedding_glove['the'], embedding_glove['cat'], embedding_glove['walks'], embedding_glove['on'], embedding_glove['the'], embedding_glove['street']))\n",
    "print(X.shape)\n",
    "#X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "X = X.view(1, X.shape[0], X.shape[1])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "unify_heads = nn.Linear(num_heads*X.shape[2], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = nn.Linear(X.shape[2], num_heads*X.shape[2], bias=False)\n",
    "keys = nn.Linear(X.shape[2], num_heads*X.shape[2], bias=False)\n",
    "values = nn.Linear(X.shape[2], num_heads*X.shape[2], bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = queries(X)\n",
    "keys = keys(X)\n",
    "values = values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Before  torch.Size([1, 6, 400])\nAfter  torch.Size([1, 6, 8, 50])\n"
    }
   ],
   "source": [
    "print(\"Before \",queries.shape)\n",
    "queries = queries.view(1, X.shape[1], num_heads, X.shape[2])\n",
    "print(\"After \", queries.shape)\n",
    "keys = keys.view(1, X.shape[1], num_heads, X.shape[2])\n",
    "values = values.view(1, X.shape[1], num_heads, X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Before  torch.Size([1, 6, 8, 50])\nAfter  torch.Size([8, 6, 50])\n"
    }
   ],
   "source": [
    "print(\"Before \",queries.shape)\n",
    "queries = queries.transpose(1, 2).contiguous().view(1*num_heads, X.shape[1], X.shape[2])\n",
    "print(\"After \", queries.shape)\n",
    "keys = keys.transpose(1, 2).contiguous().view(1*num_heads, X.shape[1], X.shape[2])\n",
    "values = values.transpose(1, 2).contiguous().view(1*num_heads, X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([8, 6, 6])\n"
    }
   ],
   "source": [
    "queries = queries/(X.shape[2]**(1/4))\n",
    "keys = keys/(X.shape[2]**(1/4))\n",
    "\n",
    "raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n",
    "print(raw_weights.shape)\n",
    "\n",
    "weights = F.softmax(raw_weights, dim=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.transpose(1, 2).contiguous().view(1, X.shape[1], num_heads*X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unify_heads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 6, 50])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ]
}